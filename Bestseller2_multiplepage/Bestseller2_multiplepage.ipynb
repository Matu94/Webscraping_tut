{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e76f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understand the magic in the previus task\n",
    "dates = ['cica', 'kutya', 'mérésihiba']\n",
    "dates = [date.upper() for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4efc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CICA', 'KUTYA', 'MÉRÉSIHIBA']\n"
     ]
    }
   ],
   "source": [
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77d2de",
   "metadata": {},
   "source": [
    "# Webscraping multiple pages\n",
    "https://data36.com/scrape-multiple-web-pages-beautiful-soup-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7081b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d4761",
   "metadata": {},
   "source": [
    "## Collecting all bestseller book titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d12e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bookdepository.com/bestsellers?page=1\n",
      "https://www.bookdepository.com/bestsellers?page=2\n",
      "https://www.bookdepository.com/bestsellers?page=3\n",
      "https://www.bookdepository.com/bestsellers?page=4\n",
      "https://www.bookdepository.com/bestsellers?page=5\n"
     ]
    }
   ],
   "source": [
    "#testing the method:\n",
    "page = 1\n",
    "while page != 6:\n",
    "    url = f\"https://www.bookdepository.com/bestsellers?page={page}\"\n",
    "    print(url)\n",
    "    page = page + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d73ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "titles = []\n",
    "while page != 35:\n",
    "    \n",
    "    #basic webscrape procedure\n",
    "    url = f\"https://www.bookdepository.com/bestsellers?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"lxml\")\n",
    "    \n",
    "    #get all title:\n",
    "    for h3 in soup.find_all(\"h3\", class_=\"title\"):\n",
    "        # .get_text() removes the tags like <h3>\n",
    "        # strip remove whitespaces\n",
    "        titles.append(h3.get_text(strip = True))\n",
    "    page = page + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92493c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1020"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55b87ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtitles\u001b[49m[:\u001b[38;5;241m6\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(title)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'titles' is not defined"
     ]
    }
   ],
   "source": [
    "for title in titles[:6]:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975558c",
   "metadata": {},
   "source": [
    "## Get the formats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90a502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formats = soup.find_all(\"p\", class_=\"format\")s\n",
    "# the same:\n",
    "formats = soup.select(\"div.item-info p.format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a816ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"format\">Paperback</p>,\n",
       " <p class=\"format\">Paperback</p>,\n",
       " <p class=\"format\">Paperback</p>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formats[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb649f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So it clears, like .get_text() and create a pandas series\n",
    "format_series = pd.Series(formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca9d659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Paperback]\n",
       "1    [Paperback]\n",
       "2    [Paperback]\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_series[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f656356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paperback              818\n",
       "Hardback               157\n",
       "Board book              19\n",
       "Cards                   14\n",
       "Game                     3\n",
       "Mixed media product      2\n",
       "Book                     2\n",
       "Diary                    1\n",
       "Spiral bound             1\n",
       "Toy                      1\n",
       "Novelty book             1\n",
       "Leather                  1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all formats (same method with titles):\n",
    "\n",
    "page = 1\n",
    "formats_all = []\n",
    "while page != 35:\n",
    "    url = f\"https://www.bookdepository.com/bestsellers?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"lxml\")\n",
    "    \n",
    "    formats_on_page = soup.select(\"div.item-info p.format\")\n",
    "    \n",
    "    #Add that element wich one is on scrape (index)\n",
    "    for product_format in formats_on_page:\n",
    "        formats_all.append(product_format.get_text())\n",
    "        \n",
    "    page = page + 1\n",
    "    \n",
    "formats_series = pd.Series(formats_all)\n",
    "formats_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c03a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paperback              0.801961\n",
       "Hardback               0.153922\n",
       "Board book             0.018627\n",
       "Cards                  0.013725\n",
       "Game                   0.002941\n",
       "Mixed media product    0.001961\n",
       "Book                   0.001961\n",
       "Diary                  0.000980\n",
       "Spiral bound           0.000980\n",
       "Toy                    0.000980\n",
       "Novelty book           0.000980\n",
       "Leather                0.000980\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the percentage value:\n",
    "formats_series.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56337a",
   "metadata": {},
   "source": [
    "## Getting publication dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596defd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021    210\n",
       "2022    182\n",
       "2020    116\n",
       "2018     91\n",
       "2019     75\n",
       "2017     53\n",
       "2016     49\n",
       "2015     44\n",
       "2011     38\n",
       "2012     26\n",
       "2014     25\n",
       "2013     19\n",
       "2009     12\n",
       "2010     11\n",
       "2007      9\n",
       "1997      8\n",
       "2008      7\n",
       "2005      7\n",
       "2000      6\n",
       "2002      5\n",
       "2006      5\n",
       "2004      4\n",
       "2003      3\n",
       "1995      3\n",
       "1998      2\n",
       "1994      2\n",
       "1999      2\n",
       "1991      2\n",
       "1968      1\n",
       "1996      1\n",
       "1992      1\n",
       "1982      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = 1\n",
    "dates = []\n",
    "while page != 35:\n",
    "    url = f\"https://www.bookdepository.com/bestsellers?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"lxml\")\n",
    "    dates_on_page = soup.find_all(\"p\", class_=\"published\")\n",
    "    \n",
    "    for date in dates_on_page:\n",
    "        dates.append((date.get_text()[-4:]))\n",
    "\n",
    "    page = page + 1\n",
    "    \n",
    "dates_series = pd.Series(dates)\n",
    "dates_series.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ea9e8",
   "metadata": {},
   "source": [
    "## Getting Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fafb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prices = []\n",
    "prices = soup.find_all(\"p\", class_=\"price\")\n",
    "\n",
    "for price in prices:\n",
    "    original_price = price.find(\"span\", class_=\"rrp\")\n",
    "    if original_price:\n",
    "        current_price = str(original_price.previousSibling).strip()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc54cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3\\xa0497 Ft'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f04e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d01622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#somehowe have to change the value of currency, but it's not the easyest thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471c3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "    url = f\"https://www.bookdepository.com/bestsellers?page=1\"\n",
    "    headers = {\"Accept-Language\": \"en-US,en;q=0.5\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.content\n",
    "    soup = bs(html, \"lxml\")\n",
    "    valuta = soup.find_all(\"option\", selected=\"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33414a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<option selected=\"selected\" value=\"en_US\">\n",
       "                     English</option>,\n",
       " <option selected=\"selected\" value=\"HUF\">\n",
       " \t\t\t\t\tFt HUF</option>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuta "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acbe8d",
   "metadata": {},
   "source": [
    "# Full code\n",
    "## can't get the price cos of location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "166faef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "\n",
    "#this will be a list of dictionary:\n",
    "bestseller_books = []\n",
    "\n",
    "#first 35 pages:\n",
    "while page != 35:\n",
    "    \n",
    "    #with f\"{}\" -arg add a variable\n",
    "      url = f\"https://www.bookdepository.com/bestsellers?page={page}\"\n",
    "      response = requests.get(url)\n",
    "      html = response.content\n",
    "      soup = bs(html, \"lxml\")\n",
    "    \n",
    "    #Find every book in the given page\n",
    "      for book in soup.find_all(\"div\", class_=\"book-item\"):\n",
    "            \n",
    "            #create a dictionary then save title, format and year:\n",
    "            #this will be added to the list\n",
    "            bestseller_book = {}\n",
    "            bestseller_book[\"title\"] = book.h3.get_text(strip=True)\n",
    "            bestseller_book[\"format\"] = book.find(\"p\", class_=\"format\").get_text()\n",
    "            \n",
    "            #year saving try\n",
    "            try:\n",
    "                  bestseller_book[\"year\"] = book.find(\"p\", class_=\"published\").get_text()[-4:]\n",
    "            #if there is no publ. info, we recive an attributeerror: 'NoneType' object...:\n",
    "            except AttributeError:\n",
    "                  bestseller_book[\"year\"] = \"\"\n",
    "                    \n",
    "                    \n",
    "            #price = book.find(\"p\", class_=\"price\")\n",
    "            #try:\n",
    "            #      original_price = price.find(\"span\", class_=\"rrp\")\n",
    "            #except AttributeError:\n",
    "            #      bestseller_book[\"price\"] = \"\"\n",
    "            #else:\n",
    "            #      if original_price:\n",
    "            #             current_price = str(original_price.previousSibling).strip()\n",
    "            #            current_price = float(current_price.split(\"€\")[0].replace(\",\", \".\"))\n",
    "            #      else:\n",
    "            #            current_price = float(price.get_text(strip=True).split(\"€\")[0].replace(\",\", \".\"))\n",
    "            #     bestseller_book[\"price\"] = current_price\n",
    "            \n",
    "            \n",
    "            bestseller_books.append(bestseller_book)\n",
    "      page = page + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98cc12c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'The Appeal', 'format': 'Paperback', 'year': '2021'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestseller_book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71843ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
